\section{Paradigma del \emph{Dynamic Programming}}

\subsection{Introduzione}

% TODO disegno albero TD BU pag 53.2
Il problema del memorylessness del paradigma \emph{Divide and Conquer} è già stato sottolineato nella sezione \ref{sss:alberochiamate}.
Per esemplificare il problema, si introduce la sequnza di Fibonacci, definita come
\begin{equation*}
    F_n = 
    \begin{cases}
        1 & n=0,1 \\
        F_{n-1} + F_{n-2} & n>1
    \end{cases}
\end{equation*}
da cui si ricava immediatamente un algoritmo ricorsivo
\begin{algorithm}[H]
\caption{Fibonacci ricorsivo}\label{alg:rfib}
\begin{algorithmic}[1]
    \Procedure{R\_FIB}{$n$}
        \If{$ n=0 $ or $n=1$}
            \State return $1$
        \EndIf
        \State return \Call{R\_FIB}{$n-1$} + \Call{R\_FIB}{$n-2$}
    \EndProcedure
\end{algorithmic}
\end{algorithm}
% TODO disegno albero chiamate R_FIB pag 53.4
\noindent
la cui equazione di ricorrenza è
\begin{equation*}
    T_{RF}(n) = 
    \begin{cases}
        0 & n=0,1 \\
        T_{RF}(n-1) + T_{RF}(n-2) + 1 & n>1
    \end{cases}
\end{equation*}
che risulta limitata inferiormente da un esponenziale, infatti per $n>1$
\begin{align*}
    T_{RF}(n) 
    &= T_{RF}(n-1) + T_{RF}(n-2) + 1 \\
    & \geq \, 2 T_{RF}(n-2) + 1 \\
    & \geq \, 2^2 T_{RF}(n-2-2) + 2 + 1 \\
    & \geq \, 2^i T_{RF}(n-2i) + \sum_{j=0}^{i-1} 2^j \\
    \intertext{che raggiunge il caso base quando $n-2i=0$ o $n-2i=1$ per $i= \left\lfloor n/2 \right\rfloor $ sia nel caso di $n$ pari sia nel caso di $n$ dispari}
    & \geq \, 2^{\left\lfloor n/2 \right\rfloor} \cancel{ T_{RF}(0 \text{ o } 1)}
    + \sum_{j=0}^{\left\lfloor n/2 \right\rfloor -1} 2^j \\
    &= 2^{\left\lfloor n/2 \right\rfloor} -1 \\
    &=  \Omega \left( 2^{n/2} \right) = \sqrt{2}^{\,n}
    \intertext{ed essendo $\sqrt{2}>1$ cresce più velocemente di ogni polinomio. Il valore esatto di $T_{RF}$ è}
    T_{RF}(n) &= \Theta \left( \left( \frac{1+\sqrt{5}}{2} \right)^n \right)
\end{align*}

Il sugo della storia è che viene calcolata un numero molto elevato di volte la stessa sottoistanza. Ispirandosi alla fase \emph{Bottom-Up} del \emph{D\&C}, e sfruttando strutture dati che contengano le informazioni necessarie, si può scrivere un algoritmo iterativo che risolve il problema.
\begin{algorithm}[H]
\caption{Fibonacci iterativo}\label{alg:itfib}
\begin{algorithmic}[1]
    \Procedure{IT\_FIB}{$n$}
        \If{$ n=0 $ or $n=1$}
            \State return $1$
        \EndIf
        \State $F[0] \gets 1$
        \State $F[1] \gets 1$
        \For{$i \gets 2 $ to $ n $ } 
            \State $F[i] \gets F[i-1] + F[i-2]$
        \EndFor
        \State return $F[n]$
    \EndProcedure
\end{algorithmic}
\end{algorithm}
\noindent
dove le soluzioni intermedie sono salvate in $F$. In realtà sarebbe sufficiente memorizzare solo gli ultimi due valori della sequenza.

Si può quindi introdurre il paradigma del \emph{Dynamic Programming}, basandosi su queste osservazioni.

\subsection{Paradigma del \emph{Dynamic Programming}}
% \subsection{Introduzione}
I due concetti fondamentali su cui si basa il paradigma \emph{Dynamic Programming} sono
\begin{itemize}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
    \item[--] dotare di memoria l'algoritmo
    \item[--] implementare la computazione in direzione \emph{bottom-up} (tutti i dati necessari sono già stati calcolati nelle iterazioni precedenti)
\end{itemize}
In ogni caso si lavora con la proprietà di sottostruttura, generando la soluzione ad un'istanza in funzione di sottoistanze di taglia minore.

Il vantaggi sono una maggiore velocità dovuta al non replicare la computazione, gli svantaggi sono legati al dover implementare la computazione in maniera da essere sicuri di avere a disposizione le soluzioni necessarie al momento giusto, che per casi articolati non è triviale. Si può sfruttare la convenienza della fase \emph{top-down}, che genera e risolve le istanze in modo coerente, scrivendo l'algoritmo in maniera ricorsiva e dotandolo di memoria, come descritto nella sezione seguente.

\section{Memoizzazione di un algoritmo ricorsivo}

È possibile modificare un algoritmo ricorsivo \emph{D\&C} memorizzando le soluzioni intermedie attraverso un processo di memoizzazione.

\subsection{Metodo generale}

Un algoritmo memoizzato è costituito da due subroutine:
\begin{enumerate}
    \item \textbf{Routine di inizializzazione} INIT\_\{AlgName\}
        \begin{itemize}
            \item risolve i casi di base direttamente
            \item inizializza una struttura tabellare \emph{globale} con
                \begin{itemize}
                    \item valori delle istanze di base, nelle locazioni associate alle istanze di base
                    \item valori di default in posizioni associate a istanze non di base (il valore di default deve essere scelto in modo da far capire che non è stato ancora calcolato)
                \end{itemize}
            \item invoca la seconda procedura (ricorsiva) \\ % FORMATTA
        \end{itemize}
    \item \textbf{Routine ricorsiva} REC\_\{AlgName\}($i$)
        \begin{itemize}
            \item controlla sulla tabella per vedere se $i$ è già stata risolta
                \begin{itemize}
                    \item se sì la ritorna
                    \item se no
                        \begin{itemize}
                            \item la calcola con la proprietà di sottostruttura
                            \item la memorizza nella tabella
                            \item la ritorna
                        \end{itemize}
                \end{itemize}
        \end{itemize}
\end{enumerate}

\textbf{Nota:} lo spazio delle sottoistanze deve essere 
\begin{itemize}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
    \item[--] piccolo
    \item[--] facilmente indicizzabile
\end{itemize}

\subsection{Algoritmo di Fibonacci memoizzato}

Per l'algoritmo di Fibonacci le due funzioni risultano
\begin{algorithm}[H]
\caption{Fibonacci memoizzato}\label{alg:fibmemoizzato}
\begin{algorithmic}[1]
    \Procedure{INIT\_FIB}{$n$}
        \If{$ n=0 $ or $n=1$}
            \State return $1$
        \EndIf
        \State $F[0] \gets 1$, $F[1] \gets 1$
        % \State $F[1] \gets 1$
        \For{$i \gets 2 $ to $ n $ } 
            \State $F[i] \gets 0$
        \EndFor
        \State return \Call{REC\_FIB}{$n$}
    \EndProcedure
    \Procedure{REC\_FIB}{$n$}
        \If{$F[i] = 0$}
            \State $F[i] \gets \Call{REC\_FIB}{i-1} + \Call{REC\_FIB}{i-2} $
        \EndIf
        \State return $F[i]$
    \EndProcedure
\end{algorithmic}
\end{algorithm}
Note:
$n$ è un parametro attuale, il valore che si vuole calcolare, mentre $i$ è un parametro formale, che descrive la generica sottoistanza su cui lavora l'algoritmo ricorsivo.
Nella funzione ricorsiva si testa se la struttura tabellare contiene già la soluzione della sottoistanza, e se no lo si calcola con l'algoritmo ricorsivo e lo si salva. Nelle successive chiamate il test fallisce e non è necessario calcolare nuovamente il valore.
Il \emph{caveat} nel dare memoria a un algoritmo \emph{D\&C} è che in lo spazio delle sottoistanze deve essere molto piccolo, in questo caso una sola sottoistanza per ogni valore di $n$. Inoltre perché l'algoritmo sia efficiente lo spazio delle possibili sottoistanze da risolvere deve essere facilmente indirizzabile e salvabile in una struttura dati semplici.

Analisi della complessità:
La ricorrenza non riesce a catturare il fatto che l'albero delle chiamate venga tagliato ogniqualvolta il valore di una sottoistanza sia stato calcolato precedentemente.
% TODO albero delle chiamate memoizzato pag 55.9
Per la fase di inizializzazione, il numero di operazioni aritmetiche che vengono eseguite è nullo.
Dall'albero delle chiamate della procedura ricorsiva con memoria, si nota che l'albero è diventato molto più snello, e sono comparse foglie dove prima erano presenti sottoalberi. Inoltre il numero di nodi interni, gli unici rispetto a cui viene fatto lavoro, sono pari al numero di sottoistanze \emph{distinte} che vanno risolte per ottenere l'istanza $n$. 
Solo nel nodo interno si esegue il conquer (la somma) associato ad ogni chiamata e la complessità sarà corrispondente al numero di nodi interni per il lavoro compiuto in ciascun nodo. C'è un nodo interno per ogni chiamata \emph{non} di base, tutte le altre sono chiamate che hanno trovato il valore in $F$ e non hanno compiuto lavoro, se non un \emph{lookup} nella tabella.
\begin{equation*}
    T_{RF} (n) = n-2+1 = n-1
\end{equation*}

\section{Paradigma generale \emph{Dynamic Programming}}

\subsection{Problemi di ottimizzazione combinatoria}

Ricordiamo la definizione di problema computazionale $\bpi{} \subseteq \bi{} \times \bs{}$

Si può definire per ogni istanza un sottoinsieme $\bs{}(i)$ formato da tutte le possibili soluzioni di quell'istanza, ricordando che una sottoistanza può ammetere più soluzioni.
\begin{equation*}
    \forall i \in \bs{} \quad S(i) = \left\{ s \in \bs{} : i \, \bpi{} \, s \right\}
\end{equation*}

Definiamo inoltre una funzione di costo che va da S in un qualche insieme totalmente ordinato.
\begin{equation*}
    c : \bs{} \to \mathbb{R}
\end{equation*}

Data $i$ un istanza generica, si vuole determinare non solo una soluzione $s \in \bs{}(i)$, ma individuare $s^*$ che massimizza (o minimizza) il criterio del costo.
\begin{equation*}
    c(s^*) = \max \left\{ c(s) : s \in \bs{}(i) \right\}
\end{equation*}

\subsection{Caratteristiche di problemi di ottimizzazione risolubili con la programmazione dinamica}

Un problema si presta ad essere risolto con la programamzione dinamica se presenta la seguente proprietà di sottostruttura ottima, che per un prolbema di ottimizzazione è una proprietà molto più ristretta rispetto a quella necessaria per il \emph{D\&C}. Infatti mette in relazione soluzioni ottime di un istanza a soluzioni ottime di sottoistanze. Questa proprietà si dice anche \emph{optimal substructure property}.

% Dare paradigmi generali che si applicano quando un problema va approcciato con la programamzione dinamica.

% Come nel dnc si sviluppa una proprietà di sottostruttura, possiamo seguire una serie di indicazioni generali che si possono istanziare volta per volta che conducono in maniera ordinata alla risuluzone di un problema con la prog dinanica. 

% Quando si decide di usare la prog dinamica?

\begin{definition}[Proprietà di sottostruttura ottima]
    Un problema gode della proprietà di sottostruttura ottima se
    \begin{enumerate}
        \item la soluzione ottima di un'istanza non di base si ottiene combinando soluzioni ottime di sottoistanze
        \item la proprietà di sottostruttura ottima genera sottoproblemi ripetuti
        \item lo spazio delle sottoistanze generate da una data istanza non è troppo grande
    \end{enumerate}
\end{definition}

Se la proprietà 2 manca, si può applicare il \emph{D\&C} classico e la programamzione dinamica non aiuterebbe.
La proprietà 3 assicura l'efficienza del paradigma, il concetto è arbitrario per ora, se non esiste una struttura dati che riesca a memorizzare in maniera efficiente i risultati intermedi, il metodo avrà risultati peggiori. In genere la dimensionalità della struttura è pari al numero di sottoistanze generate (e.g. istanze di taglia $|i|=n$ generano $n^2$ sottoistanze salvate in un array bidimensionale ).

\subsection{Paradigma generale}

Presentiamo un paradigma generale per la programmazione dinamica, enumerando i passi da seguire per sviluppare un programma secondo il \emph{dynamic programming}, garantendo implicitamente la correttezza del codice.

\begin{enumerate}
    \item caratterizza la struttura di una soluzione ottima $s^*$ a un'istanza $i$ non di base in funzione di soluzioni ottime $s_1^*, s_2^*, \cdots, s_k^*$ di sottoistanze di $i$
    \item
        \begin{enumerate}
            \item determina una relazione di ricorrenza sui costi di istanza e sottoistanza, mettendo in relazione il costo di un'istanza come una funzione dei costi delle sottoistanze \\ $c(s^*)=f\left(c(s_1^*),c(s_2^*),\cdots,c(s_k^*)\right)$
                \label{enum:pd1}
            \item determina la minima informazione strutturale necessaria ad ottenere $s^*$ a partire da $s_1^*, s_2^*, \cdots, s_k^*$, cercando di memorizzare incrementi, e non le intere soluzioni di sottoistanze
                \label{enum:pd2}
        \end{enumerate}
    \item
        \begin{enumerate}
            \item calcola il costo $c(s^*)$ utilizzando la ricorrenza impostando la computazione
                \begin{itemize}
                    \item in maniera \emph{bottom-up} iterativa
                    \item in maniera memoizzata
                \end{itemize}
                \label{enum:pd3}
            \item calcola l'informazione addizionale strutturale per ottenere $s^*$ e memorizzarla
                \label{enum:pd4}
        \end{enumerate}
\end{enumerate}

I punti \ref{enum:pd2}, \ref{enum:pd4} sono necessari solo quando si è interessati anche alla soluzione ottima, mentre \ref{enum:pd1}, \ref{enum:pd3} sono sufficienti per ricavare il costo della soluzione ottima.

\section{Ricerca della \emph{Longest Common Subsequence}}

\subsection{Sottostringhe e sottosequenze}

\subsubsection{Notazione}

\begin{itemize}
    \item[--] $\Sigma$ un alfabeto finito di simboli
    \item[--] $\Sigma^{*}$ la sua stella di \emph{Kleene}, l'insieme infinito di concatenazioni finite di simboli in $\Sigma$
    \item[--] $X = < x_1, x_2, \cdots, x_m > \in \Sigma^{*}$ una stringa di lunghezza $m = |X|$
    \item[--] $X = \varepsilon$ la stringa vuota
\end{itemize}

\subsubsection{Prefisso, suffisso, sottostringa}

\begin{definition}[Prefisso]
    Data una stringa $X$ con $|X|=m$ 
    un prefisso proprio
    è formato dai primi $i$ simboli di $X$.
    \[
        {X_i = < x_1, \cdots, x_i >}
        \quad \text{con} \quad
        1 \leq i \leq m
    \]
    Il prefisso improprio $X_0$ è definito come la stringa vuota.
    \label{def:prefisso}
\end{definition}

\begin{definition}[Suffisso]
    Data una stringa $X$ con $|X|=m$ 
    un suffisso proprio
    è formato dagli ultimi $j$ simboli di $X$.
    \[
        {X^j = < x_j, \cdots, x_m >}
        \quad \text{con} \quad
        1 \leq j \leq m
    \]
    Il prefisso improprio $X^{m+j}$ è definito come la stringa vuota.
    \label{def:suffisso}
\end{definition}

\begin{definition}[Sottostringa]
    Data una stringa $X$ con $|X|=m$ 
    una sottostringa
    è formata da $j-i+1$ simboli contigui di $X$.
    \[
        X_{i..j} = < x_i, \cdots, x_j >
        \quad \text{con} \quad
        1 \leq i \leq j \leq m
    \]
    Se $i>j$, $X_{i..j}=\varepsilon$
    \label{def:sottostringa}
\end{definition}

Lo spazio delle sottoistanze di una stringa $|X|=m$ risulta
\begin{align*}
    1 + \sum_{i=1}^{m} \sum_{j=i+1}^{m} 1 
    &= 
    1 + \sum_{i=1}^{m} \left( m-i+1 \right)
    &
    i'=m-i+1
    \\
    &=
    1 + \sum_{i'=1}^{m} i' 
    \\
    &=
    1 + \frac{m\left( m+1 \right)}{2}
    \\
    &=
    \Theta \left( m^2 \right)
\end{align*}
dove avendo già considerata una volta la sottostringa impropria, l'indice $i$ può variare a piacimento, mentre l'indice $j$ ne è sempre maggiore.

\subsubsection{Sottosequenza}

\begin{definition}[Sottosequenza]
    Data una stringa $X$ con $|X|=m$,
    $Z = < z_1, \cdots, z_k >$ è una sottosequenza di $X$ se esiste una successione di indici crescente
    % $
    \[
    1 \leq i_1 < i_2 < \cdots < i_k \leq m
    \]
    % $
    tale che 
    $z_j = x_{i_j}$, $1 \leq j \leq k$
    % \\
    , ed è la successione di indici crescente che \emph{realizza} $Z$ in $X$
    \label{def:sottosequenza}
\end{definition}

Per esempio, sia $X = <A,B,C,B,B,D>$, una sua sottostringa è $Z_1 = X_{1..3} = <A,B,C>$ mentre una sua sottosequenza è $Z_2 = <A,C,B>$. La stessa sottosequenza può essere realizzata da più successioni di indici, infatti: $i_1=1, \, i_2=3, \, i_3=\left\{ 4,5 \right\}$

Una sottostringa è sempre anche una sottosequenza, infatti $X_{k..s}$ è realizzata da $i_1=k, \, i_2=k+1, \, \cdots, \, i_{s-k+1}=s$

Lo spazio delle sottoistanze è considerevolmente più ampio, infatti il numero di possibili sottoinsiemi ordinati di indici $S \subseteq \left\{ 1, \cdots, m \right\}$, che quindi generano una sottosequenza valida, è pari a $2^m$.

\subsection{Definizione del problema}

Si può quindi introdurre il problema della ricerca della sottosequenza comune \emph{più lunga} tra due stringhe. Formalmente:

\begin{definition}
    Data un'istanza $(X,Y) \in \Sigma^* \times \Sigma^*$, con
    $ X = < x_1, \cdots, x_m > $ e 
    $ Y = < y_1, \cdots, y_n > $,
    allora
    $ Z = < z_1, \cdots, z_k > $
    è sottosequenza comune di $X$ e $Y$ se $Z$ è sottosequenza di entrambe le stringhe.
    L'obiettivo è determinare la sottosequenza comune di massima lunghezza 
    $Z^* = LCS\left( X,Y \right)$
    \label{def:lcs}
\end{definition}
Per provare che una sottosequenza sia comune è sufficiente esibire le due successioni di indici che realizzano $Z$ in $X$ e $Y$, che sia la sottosequenza di lunghezza massima viene assicurato dall'algoritmo che risolve il problema.

Spesso invece di voler individuare $Z^*$ è sufficiente conoscerne il costo $|Z^*|$, di cui si sa che $|LCS(X,Y)| < \min\left\{ m,n \right\}$.

Si può stabilire se $Z$ è sottosequenza di $X$ in tempo $\Theta \left( |X| \right)$, da cui si ricava un algoritmo naive per la ricerca della $LCS$, generando tutte le possibili sottosequenze della stringa più corta e verificando siano sottosequenze della più lunga. Se $m \leq n$, la complessità risulta $\Theta \left( 2^{m} n \right)$.

\subsection{Proprietà di sottostruttura ottima}

Supponiamo di star analizzando la sottoistanza di taglia $m+n$ relativa alle stringhe
% $ X = < x_1, \cdots, x_m > $, $ Y = < y_1, \cdots, y_n > $, e sia
\[
    X = < x_1, \cdots, x_m > \quad  Y = < y_1, \cdots, y_n >
\]
 e sia
$ Z^* = < z_1, \cdots, z_k > $
la soluzione ottima associata a questa sottoistanza. 
Soffermiamoci sull'ultimo elemento delle due stringhe:
% $ X = < X_{m-1}, a > $ e $ Y = < Y_{n-1}, b > $.
\[
     X = < X_{m-1}, a >  \quad  Y = < Y_{n-1}, b >
\]
Si possono presentare due casi.
\begin{enumerate}
    \item $a=b$: di sicuro $z_k=a=b$ e $ Z^* = < Z_{k-1}^*, a > $: intuitivamente se $Z^*$ non terminasse con $a$, esisterebbe $\hat{Z}$ di lunghezza massima che termina con $\hat{z}_k \neq a$ ed è sottosequenza di $X_{m-1}^*$ e $Y_{n-1}^*$ (non terminando con $a$), ma appendendo $a$ a $\hat{Z}$ si otterrebbe una sottosequenza più lunga, che è assurdo.
        \\
        Inoltre $Z_{k-1}^*$ sta in $X_{m-1}^*$ e $Y_{n-1}^*$, avendo già considerato l'ultimo elemento di entrambe.
        \\
        La sottoistanza generata ha taglia $m+n-2$
    \item $a \neq b$: di sicuro $z_k$ non può essere uguale ad $a$ e $b$ contemporaneamente (e può comunque essere diverso da entrambi i valori). Deve quindi verificarsi uno dei due sottocasi:
        \begin{enumerate}[label=(\roman*)]
            \item $z_k \neq a$: va risolto $LCS\left( X_{m-1}, Y \right)$
            \item $z_k \neq b$: va risolto $LCS\left( X, Y_{n-1} \right)$
        \end{enumerate}
        In entrambi i casi la sottoistanza generata ha taglia $m+n-1$
\end{enumerate}

Lo spazio dei sottoproblemi è $\left\{ \left( X_i, Y_j \right), \: 0 \leq i \leq m, \: 0 \leq j \leq n \right\}$ ed ha quindi taglia pari a $(m+1)(n+1) = \Theta (mn)$

Formalizzando la proprietà di sottostruttura ottima risulta:

\begin{lemma}[Proprietà di sottostruttura ottima]
    Per un generico sottoproblema $\left( X_i, Y_j \right), \: 0 \leq i \leq m, \: 0 \leq j \leq n$ sia 
    $ Z^* = < z_1, \cdots, z_k > = LCS\left( X_i,Y_j \right)$ allora:
    \begin{enumerate}
        \item $(i=0) \vee (j=0) \Rightarrow z^* = \varepsilon$
            \label{psolcs:casobase}
        \item $(i>0) \wedge (j>0) \wedge (x_i = y_j) \Rightarrow $
            \begin{enumerate}
                \item $z_k = x_i = y_j$
                    \label{psolcs:caso2a}
                \item $Z_{k-1}^* = LCS(X_{m-1}^*, Y_{n-1}^*)$
                    \label{psolcs:caso2b}
            \end{enumerate}
        \item $(i>0) \wedge (j>0) \wedge (x_i \neq y_j) \Rightarrow $
            \\
            $ Z^*$ è la stringa più lunga tra $LCS\left( X_{m-1}, Y \right)$ e $LCS\left( X, Y_{n-1} \right)$
    \end{enumerate}
    \label{lemma:psolcs}
\end{lemma}

La dimostrazione del caso \ref{psolcs:casobase} è immediata, infatti
\[
    LCS(\varepsilon, Y_j), LCS(X_i, \varepsilon) \Rightarrow Z^*=\varepsilon 
\]

La dimostrazione del caso \ref{psolcs:caso2a} si svolge per assurdo:

\subsection{autocomplete}
Una bella scatola:
\begin{equation}
    \boxed{x^2+y^2 = z^2}
\end{equation}

Numeri nei casi
\begin{numcases}{T(n)=}
    2^3 \label{escaso1} \\
    2^4 \label{escaso2} 
\end{numcases}

Sotto numeri
\begin{subnumcases}{T(n)=}
    2^3 \label{escaso3} \\
    2^4 
\end{subnumcases}

\begin{itemize}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
    \item qualcosa
    \item[+] qualcosa
    \item[*] qualcosa
    \item[--] qualcosa
\end{itemize}
àg
èg
ìg
òg
ùg
perché

delirio di vim se scrivi \verb|<C-k>`e| o \verb|<C-k>e`| in insert mode mette una è

% delirio doppio di vim se scrivi \verb|<C-k>da| in insert mode mette ``Hiragana letter DA'' che purtroppo non posso mostrarvi %だ
% insomma i digraph sono tanti e belli

Spazietti fra equazioni
\begin{equation*}
    A^{[0]}(x) = \sum_{j=0}^{\frac{n}{2}-1} a_{2j}x^j
    \quad \text{ e } \quad
    A^{[1]}(x) = \sum_{j=0}^{\frac{n}{2}-1} a_{2j+1}x^j
\end{equation*}

Un gustoso algoritmo
\begin{algorithm}[H]
\caption{Divide and Conquer}\label{alg:dncmock}
\begin{algorithmic}[1]
    \Procedure{D\&C}{$i$}
        \If{$|i| \leq n_0$}                             \Comment{BASE}
            \State *risolvo direttamente*
        \EndIf
        \State $<i_1, i_2, \dots, i_k> \gets A_D(i)$    \Comment{DIVIDE}
        \For{$j \gets 1 $ to $ k $ }                    \Comment{RECURSE}
            \State $s_j \gets $ \Call{D\&C}{$i_j$}
        \EndFor
        \State $s \gets A_C(<s_1, s_2, \dots, s_k>)$    \Comment{CONQUER}
        \State return $s$
    \EndProcedure
\end{algorithmic}
\end{algorithm}



